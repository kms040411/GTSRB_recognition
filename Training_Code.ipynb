{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Training Code.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kms040411/GTSRB_recognition/blob/main/Training_Code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "233ZzuutUnAn"
      },
      "source": [
        "# Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "axBUyBF-UXmP"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt # this is for importing matplotlib.pyplot (library for graph plot)\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "from PIL import Image, ImageFilter, ImageEnhance, PpmImagePlugin\n",
        "import random"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gllvn4XuUsc-"
      },
      "source": [
        "# Mount Google Drive\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LQF4DfCTUr8Q",
        "outputId": "df6993e8-4f03-4762-e026-9b90494932bd"
      },
      "source": [
        "from google.colab import files\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kLZl-_QRkA4w"
      },
      "source": [
        "# Modify Dataset\n",
        "We apply blurring, gaussian blurring, decolorization, darkening, exposure, adding noise to random image."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HHJlbOk_kXn1"
      },
      "source": [
        "## Functions\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EMdma-WJkcSK"
      },
      "source": [
        "def do_blur(img):\n",
        "    blurred = img.filter(ImageFilter.BoxBlur(2))\n",
        "    return blurred\n",
        "\n",
        "def do_gaussianblur(img):\n",
        "    blurred = img.filter(ImageFilter.GaussianBlur(2))\n",
        "    return blurred\n",
        "\n",
        "def do_decolorization(img):\n",
        "    grayscaled = img.convert(\"LA\")\n",
        "    grayscaled = grayscaled.convert(\"RGB\")\n",
        "    return grayscaled\n",
        "\n",
        "def do_darkening(img):\n",
        "    enhancer = ImageEnhance.Brightness(img)\n",
        "    darkened = enhancer.enhance(0.3)\n",
        "    return darkened\n",
        "\n",
        "def do_exposure(img):\n",
        "    enhancer = ImageEnhance.Contrast(img)\n",
        "    contrasted = enhancer.enhance(3.0)\n",
        "    enhancer2 = ImageEnhance.Brightness(contrasted)\n",
        "    exposured = enhancer.enhance(3.0)\n",
        "    return exposured\n",
        "\n",
        "def do_noise(img):\n",
        "    noisy = img.effect_spread(2)\n",
        "    return noisy"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "66tnruIWU_u-"
      },
      "source": [
        "# Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eeRuKFfLVBis"
      },
      "source": [
        "label_num = 43\n",
        "iter_num = 100\n",
        "learning_rate = 0.00005\n",
        "batch_size = 64\n",
        "\n",
        "Use_CNN = False\n",
        "Use_FRCNN = not Use_CNN\n",
        "if Use_CNN:\n",
        "  batch_size = 64\n",
        "if Use_FRCNN:\n",
        "  batch_size = 20\n",
        "\n",
        "is_continue = False\n",
        "model_path = \"/content/drive/My Drive/CS470/Project/pretrained2.ckpt\"\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gypHf9tFVw8p"
      },
      "source": [
        "# Load Dataset\n",
        "\n",
        "## Local data version"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pnsBH0dhVxP8"
      },
      "source": [
        "class GSTRB_dataset():\n",
        "  def __init__(self, root):\n",
        "    self.root = root  # path for image root folder\n",
        "    self.basic_transform = data_transforms = transforms.Compose([\n",
        "                                                                  transforms.Resize((32, 32)),\n",
        "                                                                  transforms.ToTensor(),\n",
        "                                                                  transforms.Normalize((0, 0, 0), (1, 1, 1)) # Normalize to mean=0, std=1\n",
        "                                                                ])\n",
        "\n",
        "    # Read csv\n",
        "    self.csv_list = [list() for i in range(label_num)]\n",
        "    for i in range(0, label_num):\n",
        "      label_str = None\n",
        "      if i < 10:\n",
        "        label_str = \"0000\" + str(i)\n",
        "      else:\n",
        "        label_str = \"000\" + str(i)\n",
        "        \n",
        "      folder_path = self.root + label_str\n",
        "      with open(folder_path + \"/GT-\" + label_str + \".csv\") as f:\n",
        "        line = f.readline() # Ignore First line\n",
        "        while(True):\n",
        "            line = f.readline()\n",
        "            if line == \"\":\n",
        "                break\n",
        "            splited = line.split(\";\")\n",
        "            file_name = splited[0]\n",
        "            self.csv_list[i].append(file_name)\n",
        "    \n",
        "    # Split train data and validate data\n",
        "    self.train_list = [None for i in range(label_num)]\n",
        "    self.validate_list = [None for i in range(label_num)]\n",
        "    for i in range(0, label_num):\n",
        "      total_num = len(self.csv_list[i])\n",
        "      random.shuffle(self.csv_list[i])\n",
        "      split_index = int(total_num * 0.7)\n",
        "      self.train_list[i] = self.csv_list[i][:split_index]\n",
        "      self.validate_list[i] = self.csv_list[i][split_index:]\n",
        "\n",
        "  # Select random image and its index\n",
        "  def sample_one(self, data_set):\n",
        "    # Select label first\n",
        "    label = random.randrange(0, label_num)\n",
        "    label_str = None\n",
        "    if label < 10:\n",
        "      label_str = \"0000\" + str(label)\n",
        "    else:\n",
        "      label_str = \"000\" + str(label)\n",
        "\n",
        "    folder_path = self.root + label_str\n",
        "\n",
        "    # Sample image\n",
        "    # It is possible to select the same data, but the probability is very low.\n",
        "    target = random.sample(data_set[label], 1)[0]\n",
        "    img = Image.open(folder_path + \"/\" + target)\n",
        "\n",
        "    # Apply transform\n",
        "    transforms = [do_blur, do_gaussianblur, do_decolorization, do_darkening, do_exposure, do_noise, None]\n",
        "    rand_transform = random.sample(transforms, 1)[0]\n",
        "    if rand_transform is not None:\n",
        "      img = rand_transform(img)\n",
        "\n",
        "    # Basic transfrom\n",
        "    img = self.basic_transform(img)\n",
        "    img = torch.unsqueeze(img, 0)\n",
        "    label = torch.LongTensor([label])\n",
        "\n",
        "    return (img, label)\n",
        "  \n",
        "  def sample_train(self):\n",
        "    return self.sample_one(self.train_list)\n",
        "  \n",
        "  def sample_validate(self):\n",
        "    return self.sample_one(self.validate_list)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yLQu6cCFRMeN"
      },
      "source": [
        "class GSTRB_test_dataset():\n",
        "  def __init__ (self, root):\n",
        "    self.root = root  # path for image root folder\n",
        "    self.basic_transform = data_transforms = transforms.Compose([\n",
        "                                                                  transforms.Resize((32, 32)),\n",
        "                                                                  transforms.ToTensor(),\n",
        "                                                                  transforms.Normalize((0, 0, 0), (1, 1, 1)) # Normalize to mean=0, std=1\n",
        "                                                                ])\n",
        "    # Read csv\n",
        "    self.train_list = list()\n",
        "    with open(folder_path + \"/GT-final_test.GT.csv\") as f:\n",
        "        line = f.readline() # Ignore First line\n",
        "        while(True):\n",
        "            line = f.readline()\n",
        "            if line == \"\":\n",
        "                break\n",
        "            splited = line.split(\";\")\n",
        "            file_name = splited[0]\n",
        "            label = splited[7]\n",
        "            self.csv_list[i].append((file_name, label))\n",
        "  \n",
        "  def sample_test(self):\n",
        "    target = random.sample(self.train_list, 1)[0]\n",
        "    img, label = Image.open(self.root + \"/\" + target)\n",
        "    label = int(label)\n",
        "\n",
        "    # Apply transform\n",
        "    transforms = [do_blur, do_gaussianblur, do_decolorization, do_darkening, do_exposure, do_noise, None]\n",
        "    #rand_transform = random.sample(transforms, 1)[0]\n",
        "    #if rand_transform is not None:\n",
        "    #  img = rand_transform(img)\n",
        "    \n",
        "    # Basic transfrom\n",
        "    img = self.basic_transform(img)\n",
        "    img = torch.unsqueeze(img, 0)\n",
        "    label = torch.LongTensor([label])\n",
        "\n",
        "    return (img, label)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rf8wM6EhDYiw"
      },
      "source": [
        "## Kaggle version"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "id": "ZSdfoc8KCDWl",
        "outputId": "37cbd5fc-b5a8-497f-f79f-da2094a68101"
      },
      "source": [
        "# We need to upload kaggle.json\n",
        "\n",
        "'''from google.colab import files\n",
        "files.upload()\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "# Download dataset from kaggle\n",
        "!kaggle datasets download -d meowmeowmeowmeowmeow/gtsrb-german-traffic-sign --force\n",
        "!unzip -q *.zip'''"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'from google.colab import files\\nfiles.upload()\\n!mkdir -p ~/.kaggle\\n!cp kaggle.json ~/.kaggle/\\n!chmod 600 ~/.kaggle/kaggle.json\\n\\n# Download dataset from kaggle\\n!kaggle datasets download -d meowmeowmeowmeowmeow/gtsrb-german-traffic-sign --force\\n!unzip -q *.zip'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3mK4ISvZDftG"
      },
      "source": [
        "class GSTRB_train_dataset(torch.utils.data.Dataset):\n",
        "  def __init__(self, root, csv):\n",
        "    self.root = root\n",
        "    self.csv = pd.read_csv(csv)\n",
        "    self.basic_transform = data_transforms = transforms.Compose([\n",
        "                                                              transforms.Resize((32, 32)),\n",
        "                                                              transforms.ToTensor(),\n",
        "                                                              transforms.Normalize((0.3337, 0.3064, 0.3171), ( 0.2672, 0.2564, 0.2629))\n",
        "                                                            ])\n",
        "    self.counter = 0\n",
        "    self.transform_num = 7\n",
        "    \n",
        "  def __len__(self):\n",
        "    ans = len(self.csv) * self.transform_num\n",
        "    return ans\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    image = Image.open(os.path.join(self.root, str(self.csv.iloc[idx // self.transform_num, 7])))\n",
        "    label = torch.tensor(self.csv.iloc[idx // self.transform_num, 6]).long()\n",
        "        \n",
        "    # Apply transform\n",
        "    transforms = [do_blur, do_gaussianblur, do_decolorization, do_darkening, do_exposure, do_noise, None]\n",
        "    rand_transform = transforms[self.counter]\n",
        "    self.counter = self.counter + 1\n",
        "    self.counter = self.counter % self.transform_num\n",
        "    if rand_transform is not None:\n",
        "      image = rand_transform(image)\n",
        "    image = self.basic_transform(image)\n",
        "\n",
        "    pack = (image, label)\n",
        "    return pack\n",
        "\n",
        "train_dataset, valid_dataset = None, None\n",
        "if Use_CNN:\n",
        "  dataset_loader = GSTRB_train_dataset(\"/content/\", \"/content/Train.csv\")\n",
        "\n",
        "  # Split Dataset\n",
        "  train_Num = int(0.8*len(dataset_loader))\n",
        "  valid_Num = len(dataset_loader) - train_Num\n",
        "  train_dataset, valid_dataset = torch.utils.data.random_split(dataset_loader, [train_Num, valid_Num])\n",
        "\n",
        "  train_dataset = torch.utils.data.DataLoader(train_dataset,\n",
        "                                          batch_size=batch_size,\n",
        "                                          shuffle=True,\n",
        "                                          drop_last=True\n",
        "                                          )\n",
        "  valid_dataset = torch.utils.data.DataLoader(valid_dataset,\n",
        "                                          batch_size=batch_size,\n",
        "                                          shuffle=False,\n",
        "                                          drop_last=True\n",
        "                                          )"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gqs4PX_h5bKT"
      },
      "source": [
        "## Dataset for Fast RCNN Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Cp1W21B32OX"
      },
      "source": [
        "class GTSRB_frcnn_train_dataset(torch.utils.data.Dataset):\n",
        "  def __init__(self, root, csv):\n",
        "    self.root = root\n",
        "    self.csv = pd.read_csv(csv)\n",
        "    self.basic_transform = data_transforms = transforms.Compose([\n",
        "                                                              transforms.Resize((32, 32)),\n",
        "                                                              transforms.ToTensor(),\n",
        "                                                              transforms.Normalize((0.3337, 0.3064, 0.3171), ( 0.2672, 0.2564, 0.2629))\n",
        "                                                            ])\n",
        "    self.counter = 0\n",
        "    self.transform_num = 7\n",
        "  \n",
        "  def __len__(self):\n",
        "    ans = len(self.csv) * self.transform_num\n",
        "    return ans\n",
        "  \n",
        "  def __getitem__(self, idx):\n",
        "    image = Image.open(os.path.join(self.root, str(self.csv.iloc[idx // self.transform_num, 7])))\n",
        "    label = torch.tensor([self.csv.iloc[idx // self.transform_num, 6]]).long()\n",
        "        \n",
        "    # Apply transform\n",
        "    transforms = [do_blur, do_gaussianblur, do_decolorization, do_darkening, do_exposure, do_noise, None]\n",
        "    #rand_transform = random.sample(transforms, 1)[0]\n",
        "    rand_transform = transforms[self.counter]\n",
        "    self.counter = self.counter + 1\n",
        "    self.counter = self.counter % self.transform_num\n",
        "    if rand_transform is not None:\n",
        "      image = rand_transform(image)\n",
        "    image = self.basic_transform(image)\n",
        "\n",
        "    # Get boxes\n",
        "    box = torch.tensor([[self.csv.iloc[idx // self.transform_num, 2], self.csv.iloc[idx // self.transform_num, 3], self.csv.iloc[idx // self.transform_num, 4], self.csv.iloc[idx // self.transform_num, 5]]])\n",
        "\n",
        "    pack = (image, label, box)\n",
        "    return pack\n",
        "\n",
        "train_frcnn_dataset, valid_frcnn_dataset = None, None\n",
        "if Use_FRCNN:\n",
        "  frcnn_dataset_loader = GTSRB_frcnn_train_dataset(\"/content/\", \"/content/Train.csv\")\n",
        "\n",
        "  # Split Dataset\n",
        "  train_Num = int(0.8*len(frcnn_dataset_loader))\n",
        "  valid_Num = len(frcnn_dataset_loader) - train_Num\n",
        "  train_frcnn_dataset, valid_frcnn_dataset = torch.utils.data.random_split(frcnn_dataset_loader, [train_Num, valid_Num])\n",
        "\n",
        "  train_frcnn_dataset = torch.utils.data.DataLoader(train_frcnn_dataset,\n",
        "                                          batch_size=batch_size,\n",
        "                                          shuffle=True,\n",
        "                                          drop_last=True\n",
        "                                          )\n",
        "  valid_frcnn_dataset = torch.utils.data.DataLoader(valid_frcnn_dataset,\n",
        "                                          batch_size=batch_size,\n",
        "                                          shuffle=False,\n",
        "                                          drop_last=True\n",
        "                                          )"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xy4Q6xWMV2L_"
      },
      "source": [
        "# Define Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SvgHADU83OR6"
      },
      "source": [
        "class SimpleCNN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(SimpleCNN, self).__init__()\n",
        "    # Spatial Transformation Network\n",
        "    self.localization = nn.Sequential(\n",
        "                                        nn.Conv2d(3, 8, kernel_size=7),\n",
        "                                        nn.MaxPool2d(2, stride=2),\n",
        "                                        nn.ReLU(True),\n",
        "                                        nn.Conv2d(8, 10, kernel_size=5),\n",
        "                                        nn.MaxPool2d(2, stride=2),\n",
        "                                        nn.ReLU(True)\n",
        "                                    )\n",
        "    \n",
        "    # Regressor for the affine matrix\n",
        "    self.fc_loc = nn.Sequential(\n",
        "                                  nn.Linear(10 * 4 * 4, 32),\n",
        "                                  nn.ReLU(True),\n",
        "                                  nn.Linear(32, 3 * 2)\n",
        "                              )\n",
        "\n",
        "    # CNN\n",
        "    self.conv1 = nn.Conv2d(in_channels=3, out_channels=100, kernel_size=5)\n",
        "    self.relu1 = nn.ReLU()\n",
        "    self.batchnorm1 = nn.BatchNorm2d(100)\n",
        "    self.maxpool1 = nn.MaxPool2d(2)\n",
        "    self.drop1 = nn.Dropout2d()\n",
        "    self.conv2 = nn.Conv2d(in_channels=100, out_channels=150, kernel_size=3)\n",
        "    self.relu2 = nn.ReLU()\n",
        "    self.batchnorm2 = nn.BatchNorm2d(150)\n",
        "    self.maxpool2 = nn.MaxPool2d(2)\n",
        "    self.drop2 = nn.Dropout2d()\n",
        "    self.conv3 = nn.Conv2d(in_channels=150, out_channels=250, kernel_size=3)\n",
        "    self.relu3 = nn.ReLU()\n",
        "    self.batchnorm3 = nn.BatchNorm2d(250)\n",
        "    self.maxpool3 = nn.MaxPool2d(2)\n",
        "    self.drop3 = nn.Dropout2d()\n",
        "    \n",
        "\n",
        "    # Full-Connected\n",
        "    self.fc1 = nn.Linear(250 * 2 * 2, 350)\n",
        "    self.relu4 = nn.ReLU()\n",
        "    self.fc2 = nn.Linear(350, label_num)\n",
        "    self.relu5 = nn.ReLU()\n",
        "\n",
        "  def forward(self, x):\n",
        "    output = x\n",
        "\n",
        "    # Spatial Transformation Network\n",
        "    output = self.localization(output)\n",
        "    output = output.view(-1, 10 * 4 * 4)\n",
        "    theta = self.fc_loc(output)\n",
        "    theta = theta.view(-1, 2, 3)\n",
        "    grid = torch.nn.functional.affine_grid(theta, x.size(), align_corners=False)\n",
        "    output = torch.nn.functional.grid_sample(x, grid, align_corners=False)\n",
        "\n",
        "    # CNN\n",
        "    output = self.conv1(output)\n",
        "    output = self.relu1(output)\n",
        "    output = self.maxpool1(output)\n",
        "    output = self.batchnorm1(output)\n",
        "    output = self.drop1(output)\n",
        "\n",
        "    output = self.conv2(output)\n",
        "    output = self.relu2(output)\n",
        "    output = self.maxpool2(output)\n",
        "    output = self.batchnorm2(output)\n",
        "    output = self.drop2(output)\n",
        "\n",
        "    output = self.conv3(output)\n",
        "    output = self.relu3(output)\n",
        "    output = self.maxpool3(output)\n",
        "    output = self.batchnorm3(output)\n",
        "    output = self.drop3(output)\n",
        "\n",
        "    # Full-Connected\n",
        "    output = output.view(-1, 250 * 2 * 2)\n",
        "    output = self.fc1(output)\n",
        "    output = self.relu4(output)\n",
        "    output = self.fc2(output)\n",
        "    output = self.relu5(output)\n",
        "    output = nn.functional.log_softmax(output, dim=1)\n",
        "    return output"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KgIaurJnV2iL"
      },
      "source": [
        "def weights_init(m):\n",
        "  if isinstance(m, nn.Linear) or isinstance(m, nn.Conv2d):\n",
        "    nn.init.normal_(m.weight, mean=0.5, std=1.0)\n",
        "    nn.init.normal_(m.bias, mean=0.5, std=1.0)\n",
        "\n",
        "model = None\n",
        "if Use_CNN:\n",
        "  model = SimpleCNN()\n",
        "  model = model.to(device)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bkEtg57447iI"
      },
      "source": [
        "import torchvision\n",
        "\n",
        "frcnn_model = None\n",
        "if Use_FRCNN:\n",
        "  frcnn_model = torchvision.models.detection.fasterrcnn_resnet50_fpn(num_classes=label_num)\n",
        "  frcnn_model = frcnn_model.to(device)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zZgvwBuIUZNj"
      },
      "source": [
        "# Training Code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FqUkxVxg0Hns"
      },
      "source": [
        "def label(prediction):\n",
        "  _, pred_label = torch.max(prediction, 1)\n",
        "  return pred_label\n",
        "\n",
        "def save_checkpoint(model, optimizer, epoch, model_path):\n",
        "  state = {\n",
        "      'state_dict': model,\n",
        "      'optimizer': optimizer,\n",
        "      'epoch': epoch\n",
        "  }\n",
        "  torch.save(state, model_path)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tam5GFOoUzTx"
      },
      "source": [
        "if Use_CNN:\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "  criterion = torch.nn.CrossEntropyLoss()\n",
        "  start_epoch = 1\n",
        "  if is_continue:\n",
        "    print(\"Load previous model parameters\")\n",
        "    loaded = torch.load(model_path)\n",
        "    model.load_state_dict(loaded['state_dict'])\n",
        "    optimizer.load_state_dict(loaded['optimizer'])\n",
        "    start_epoch = loaded['epoch'] + 1\n",
        "    print(\"Start from epoch:\", start_epoch)\n",
        "  else:\n",
        "    model.apply(weights_init)\n",
        "    # Initalize STN\n",
        "    model.fc_loc[2].weight.data.zero_()\n",
        "    model.fc_loc[2].bias.data = torch.tensor([1, 0, 0, 0, 1, 0], dtype=torch.float).cuda()\n",
        "\n",
        "  # For each epoch, multiply 0.95 to learning rate\n",
        "  scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma= 0.99)\n",
        "\n",
        "  # Statistics for total training\n",
        "  train_loss = np.zeros(iter_num, dtype=float)\n",
        "  validation_loss = np.zeros(iter_num, dtype=float)\n",
        "  train_accuracy = np.zeros(iter_num, dtype=float)\n",
        "  validation_accuracy = np.zeros(iter_num, dtype=float)\n",
        "\n",
        "  for iter in range(start_epoch, iter_num + start_epoch):\n",
        "    # Set training mode\n",
        "    model.train()\n",
        "\n",
        "    # Statistics for current iteration\n",
        "    current_loss = 0.0\n",
        "    total_prediction = 0.0\n",
        "    correct_prediction = 0.0\n",
        "    i = 0\n",
        "    for _, (x, answer) in enumerate(train_dataset):\n",
        "      print(\"\\r\", end=\"\")\n",
        "      i = i + 1\n",
        "      print(\"train_dataset: \",i, \"/\", len(train_dataset), end=\"\")\n",
        "      x, answer = x.cuda(), answer.cuda()\n",
        "      optimizer.zero_grad()\n",
        "      prediction = model(x)\n",
        "      loss = criterion(prediction, answer)  # We use cross entropy loss for loss calculation\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      current_loss += loss.item()\n",
        "      total_prediction += x.data.size(0)\n",
        "      correct_prediction += (label(prediction) == answer.data).sum().item()\n",
        "    \n",
        "    accuracy = correct_prediction * 100.0 / total_prediction\n",
        "    train_loss[iter - start_epoch] = current_loss / total_prediction\n",
        "    train_accuracy[iter - start_epoch] = accuracy\n",
        "\n",
        "    scheduler.step() \n",
        "    print(\"\\r\", end=\"\")\n",
        "    if iter % 1 == 0:\n",
        "      print(str(iter) + \"/\" + str(iter_num + start_epoch) + \": train loss - \" + str(train_loss[iter - start_epoch]) + \", train accuracy - \" + str(train_accuracy[iter - start_epoch]) + \"%, lr: \" + str(scheduler.get_last_lr()))\n",
        "\n",
        "    # Set validation mode\n",
        "    model.eval()\n",
        "\n",
        "    # Statistics for current iteration\n",
        "    current_loss = 0.0\n",
        "    total_prediction = 0.0\n",
        "    correct_prediction = 0.0\n",
        "    #for batch_num in range(batch_size):\n",
        "    #  x, answer = dataset.sample_validate()\n",
        "    with torch.no_grad():\n",
        "      i=0\n",
        "      for _, (x, answer) in enumerate(valid_dataset):\n",
        "        print(\"\\r\", end=\"\")\n",
        "        i = i + 1\n",
        "        print(\"valid_dataset: \",i, \"/\", len(valid_dataset), end=\"\")\n",
        "        x, answer = x.cuda(), answer.cuda()\n",
        "        prediction = model(x)\n",
        "        loss = criterion(prediction, answer)  # We use cross entropy loss for loss calculation\n",
        "\n",
        "        current_loss += loss.item()\n",
        "        total_prediction += x.data.size(0)\n",
        "        correct_prediction += (label(prediction) ==  answer.data).sum().item()\n",
        "      \n",
        "      accuracy = correct_prediction * 100.0 / total_prediction\n",
        "      train_loss[iter - start_epoch] = current_loss / total_prediction\n",
        "      train_accuracy[iter - start_epoch] = accuracy\n",
        "\n",
        "    print(\"\\r\", end=\"\")\n",
        "    if iter % 1 == 0:\n",
        "      print(str(iter) + \"/\" + str(iter_num + start_epoch) + \": validation loss - \" + str(train_loss[iter - start_epoch]) + \", validation accuracy - \" + str(train_accuracy[iter - start_epoch]) + \"%\")\n",
        "    \n",
        "    # Save checkpoint\n",
        "    if iter % 50 == 0:\n",
        "      print(\"Save Current Model Parameter\")\n",
        "      save_checkpoint(model.state_dict(), optimizer.state_dict(), iter, model_path)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vUZTjbK657z-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a5b94c4-c03c-48b8-d386-022b1055676a"
      },
      "source": [
        "if Use_FRCNN:\n",
        "  optimizer = torch.optim.Adam(frcnn_model.parameters(), lr=learning_rate)\n",
        "  start_epoch = 1\n",
        "  if is_continue:\n",
        "    print(\"Load previous model parameters\")\n",
        "    loaded = torch.load(model_path)\n",
        "    model.load_state_dict(loaded['state_dict'])\n",
        "    optimizer.load_state_dict(loaded['optimizer'])\n",
        "    start_epoch = loaded['epoch'] + 1\n",
        "\n",
        "  # For each epoch, multiply 0.95 to learning rate\n",
        "  scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma= 0.99)\n",
        "\n",
        "  # Statistics for total training\n",
        "  train_loss = np.zeros(iter_num, dtype=float)\n",
        "\n",
        "  previous_best_accurary = None\n",
        "\n",
        "  for iter in range(start_epoch, iter_num + start_epoch):\n",
        "    frcnn_model.train()\n",
        "\n",
        "    # Statistics for current iteration\n",
        "    current_loss = 0.0\n",
        "    total_prediction = 0.0\n",
        "    correct_prediction = 0.0\n",
        "    index = 0\n",
        "    for _, (x, label, box) in enumerate(train_frcnn_dataset):\n",
        "      index = index + 1\n",
        "      print(\"\\r\", end=\"\")\n",
        "      print(\"train batch: \",index, \"/\", len(train_frcnn_dataset),\" \", end=\"\")\n",
        "      x, label, box = x.to(device), label.to(device), box.to(device)\n",
        "      images = list(image for image in x)\n",
        "      targets = []\n",
        "      for i in range(len(images)):\n",
        "        d = {}\n",
        "        d['boxes'] = box[i]\n",
        "        d['labels'] = label[i]\n",
        "        targets.append(d)\n",
        "\n",
        "      prediction = frcnn_model(images, targets)\n",
        "      optimizer.zero_grad()\n",
        "      loss = prediction['loss_classifier'].mean() + prediction['loss_classifier'].mean() + prediction['loss_objectness'].mean() + prediction['loss_rpn_box_reg'].mean()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      current_loss += loss.item()\n",
        "      total_prediction += x.data.size(0)\n",
        "      del x, label, box, prediction, loss\n",
        "    \n",
        "    train_loss[iter - start_epoch] = current_loss / total_prediction\n",
        "\n",
        "    scheduler.step()\n",
        "    \n",
        "    if iter % 1 == 0:\n",
        "      print(str(iter) + \"/\" + str(iter_num + start_epoch) + \": train loss - \" + str(train_loss[iter - start_epoch]) + \", lr: \" + str(scheduler.get_last_lr()))\n",
        "    \n",
        "    # Save checkpoint\n",
        "    if iter % 50 == 0:\n",
        "      print(\"Save Current Model Parameter\")\n",
        "      save_checkpoint(frcnn_model.state_dict(), optimizer.state_dict(), iter, model_path)\n",
        "      "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train batch:  3 / 10978  "
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}